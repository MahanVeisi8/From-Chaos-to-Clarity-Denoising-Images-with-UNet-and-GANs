# -*- coding: utf-8 -*-
"""From Chaos to Clarity: Image Denoising with UNet and GANs.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Rv-XS27X-YDUu4Vv7jss0tn06V3qKEp0

# Data
"""

# Mount Google Drive
from google.colab import drive
drive.mount('/content/drive')

import os
import zipfile
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

# Path to the dataset zip file
zip_path = '/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions.zip'
extract_path = '/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data'

# Unzip the dataset
if not os.path.exists(extract_path):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall(extract_path)
    print("Dataset extracted to:", extract_path)
else:
    print("Dataset already extracted.")

# List files in the extraction directory
print("\nListing extracted files:")
for root, dirs, files in os.walk(extract_path):
    for name in files:
        print(os.path.join(root, name))

file1 = '/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/fer2013.csv'

csv_path = file1  # Choose the first file for now

data = pd.read_csv(csv_path)
print("Dataset Overview:")
print(data.head())

# Display columns and basic statistics
print("\nColumns:", data.columns)
print("\nDataset Info:")
print(data.info())

# Describe numerical data
print("\nNumerical Data Description:")
print(data.describe())

def visualize_images(data, num_samples=5):
    if 'pixels' in data.columns and 'emotion' in data.columns:
        # Randomly select samples
        samples = data.sample(num_samples)
        fig, axes = plt.subplots(1, num_samples, figsize=(15, 5))
        for i, row in enumerate(samples.iterrows()):
            pixels = row[1]['pixels']
            emotion = row[1]['emotion']
            # Convert pixel data to a 48x48 image
            image = np.array(pixels.split(), dtype=np.uint8).reshape(48, 48)
            axes[i].imshow(image, cmap='gray')
            axes[i].axis('off')
            axes[i].set_title(f"Emotion: {emotion}")
        plt.tight_layout()
        plt.show()
    else:
        print("Dataset does not have 'pixels' or 'emotion' columns.")

# Visualize some images
visualize_images(data)

# Check dataset shape
print("\nDataset Shape:")
print(data.shape)

# Verify that all rows have pixel data
print("\nMissing Pixel Data:")
missing_pixels = data['pixels'].isnull().sum()
print(f"Missing pixel entries: {missing_pixels}")

# Inspect the pixel data format
print("\nSample Pixel Data Format:")
print(data['pixels'].iloc[0])

# Convert pixel data to numpy arrays and inspect shapes
def check_image_shapes(data, num_samples=5):
    sample_images = []
    print("\nInspecting Shapes of Images:")
    for i in range(num_samples):
        # Randomly pick a row
        row = data.sample(1).iloc[0]
        pixels = np.array(row['pixels'].split(), dtype=np.uint8).reshape(48, 48)
        sample_images.append(pixels)
        print(f"Image {i+1}: {pixels.shape}")
    return sample_images

# Check a few sample shapes
sample_images = check_image_shapes(data)

# Visualize the sample images
print("\nVisualizing Sample Images:")
fig, axes = plt.subplots(1, len(sample_images), figsize=(15, 5))
for i, img in enumerate(sample_images):
    axes[i].imshow(img, cmap='gray')
    axes[i].axis('off')
    axes[i].set_title(f"Sample {i+1}")
plt.tight_layout()
plt.show()

# Filter data based on the `Usage` column
train_data = data[data['Usage'] == 'Training']  # Predefined training set
val_data = data[data['Usage'] == 'PublicTest']  # Predefined validation set
test_data = data[data['Usage'] == 'PrivateTest']  # Predefined test set

# Drop unnecessary columns for this task
train_data = train_data.drop(columns=['emotion', 'Usage'])
val_data = val_data.drop(columns=['emotion', 'Usage'])
test_data = test_data.drop(columns=['emotion', 'Usage'])

# Verify the splits
print(f"Training Set: {train_data.shape}")
print(f"Validation Set: {val_data.shape}")
print(f"Test Set: {test_data.shape}")

import torch
from torch.utils.data import Dataset, DataLoader
import torchvision.transforms as transforms
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
import os

# Define device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define global variables
batch_size = 64
num_workers = 2

from torch.utils.data import Dataset
import numpy as np

# Custom Dataset for Noisy and Clean Image Pairs
class NoisyDataset(Dataset):
    def __init__(self, data, transform=None, noise_factor=0.2, noise_std=0.5, noise_type='gaussian', salt_pepper_ratio=0.5):
        """
        Args:
            data (pd.DataFrame): Input data containing image pixels as strings.
            transform (callable, optional): Optional transform to be applied to each image.
            noise_factor (float): Scaling factor for noise intensity.
            noise_std (float): Standard deviation for Gaussian noise.
            noise_type (str): Type of noise ('gaussian' or 'salt_pepper').
            salt_pepper_ratio (float): Ratio of salt (white) to pepper (black) noise in Salt-and-Pepper noise.
        """
        self.data = data
        self.transform = transform
        self.noise_factor = noise_factor
        self.noise_std = noise_std
        self.noise_type = noise_type
        self.salt_pepper_ratio = salt_pepper_ratio

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        # Parse the image from the dataset
        pixels = self.data.iloc[idx]['pixels']
        image = np.array(pixels.split(), dtype=np.float32).reshape(48, 48)  # Ensure `float32` dtype

        # Normalize the clean image to [-1, 1]
        clean_image = image / 127.5 - 1.0

        # Add noise to the image
        noisy_image = self._apply_noise(clean_image)

        # Apply optional transforms (e.g., for tensor conversion)
        if self.transform:
            clean_image = self.transform(clean_image)
            noisy_image = self.transform(noisy_image)

        return noisy_image, clean_image

    def _apply_noise(self, clean_image):
        """
        Applies the specified noise type to the image.
        Args:
            clean_image (np.ndarray): The clean image to which noise is added.
        Returns:
            np.ndarray: Noisy image.
        """
        if self.noise_type == 'gaussian':
            noise = np.random.normal(loc=0.0, scale=self.noise_std, size=clean_image.shape).astype(np.float32)
            noisy_image = clean_image + self.noise_factor * noise
        elif self.noise_type == 'salt_pepper':
            noisy_image = self._add_salt_pepper_noise(clean_image)
        else:
            raise ValueError(f"Unsupported noise type: {self.noise_type}")

        # Clip values to [-1, 1] after adding noise
        return np.clip(noisy_image, -1.0, 1.0)

    def _add_salt_pepper_noise(self, clean_image):
        """
        Adds Salt-and-Pepper noise to the image.
        Args:
            clean_image (np.ndarray): The clean image to which noise is added.
        Returns:
            np.ndarray: Noisy image.
        """
        noisy_image = clean_image.copy()
        num_pixels = clean_image.size

        # Calculate the number of salt and pepper pixels
        num_salt = int(num_pixels * self.noise_factor * self.salt_pepper_ratio)
        num_pepper = int(num_pixels * self.noise_factor * (1 - self.salt_pepper_ratio))

        # Add salt (white) noise
        salt_coords = [np.random.randint(0, dim, num_salt) for dim in clean_image.shape]
        noisy_image[salt_coords[0], salt_coords[1]] = 1.0

        # Add pepper (black) noise
        pepper_coords = [np.random.randint(0, dim, num_pepper) for dim in clean_image.shape]
        noisy_image[pepper_coords[0], pepper_coords[1]] = -1.0

        return noisy_image

# Create datasets
def create_datasets(data, noise_levels, transform=None):
    datasets = {}
    for noise_config in noise_levels:
        name = noise_config['name']
        datasets[name] = NoisyDataset(
            data=data,
            transform=transform,
            noise_factor=noise_config.get('factor', 0.2),
            noise_std=noise_config.get('std', 0.5),
            noise_type=noise_config.get('type', 'gaussian'),
            salt_pepper_ratio=noise_config.get('salt_pepper_ratio', 0.5)
        )
    return datasets

# Create dataloaders
def create_dataloaders(datasets, batch_size, num_workers):
    loaders = {
        name: DataLoader(dataset, batch_size=batch_size, shuffle=(name == 'low_gaussian_noise'), num_workers=num_workers)
        for name, dataset in datasets.items()
    }
    return loaders

# Visualization for noisy and clean pairs
def visualize_noisy_clean(loader, num_samples=5):
    data_iter = iter(loader)
    noisy_images, clean_images = next(data_iter)

    fig, axes = plt.subplots(2, num_samples, figsize=(15, 6))
    for i in range(num_samples):
        # Noisy image
        axes[0, i].imshow(noisy_images[i].squeeze().numpy(), cmap='gray')
        axes[0, i].axis('off')
        axes[0, i].set_title("Noisy")

        # Clean image
        axes[1, i].imshow(clean_images[i].squeeze().numpy(), cmap='gray')
        axes[1, i].axis('off')
        axes[1, i].set_title("Clean")

    plt.tight_layout()
    plt.show()

# Define transforms
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize(mean=(0.5,), std=(0.5,))
])

# Define noise levels
noise_levels = [
    {'name': 'low_gaussian_noise', 'factor': 0.2, 'std': 0.2, 'type': 'gaussian'},
    {'name': 'high_gaussian_noise', 'factor': 0.3, 'std': 0.4, 'type': 'gaussian'},
    {'name': 'salt_pepper_noise', 'factor': 0.1, 'type': 'salt_pepper', 'salt_pepper_ratio': 0.5}
]

# Prepare datasets
train_datasets = create_datasets(train_data, noise_levels, transform=transform)
val_datasets = create_datasets(val_data, noise_levels, transform=transform)
test_datasets = create_datasets(test_data, noise_levels, transform=transform)

# Create dataloaders
train_loaders = create_dataloaders(train_datasets, batch_size=batch_size, num_workers=num_workers)
val_loaders = create_dataloaders(val_datasets, batch_size=batch_size, num_workers=num_workers)
test_loaders = create_dataloaders(test_datasets, batch_size=batch_size, num_workers=num_workers)

# Visualize samples
print("Visualizing Gaussian noise (low):")
visualize_noisy_clean(train_loaders['low_gaussian_noise'])

print("Visualizing Gaussian noise (high):")
visualize_noisy_clean(train_loaders['high_gaussian_noise'])

print("Visualizing Salt-and-Pepper noise:")
visualize_noisy_clean(train_loaders['salt_pepper_noise'])

"""# Model

## 1: AttentionUnet
"""

import torch
import torch.nn as nn

# Attention Block
class AttentionBlock(nn.Module):
    def __init__(self, in_channels, g_channels, inter_channels):
        super(AttentionBlock, self).__init__()
        self.theta = nn.Conv2d(in_channels, inter_channels, kernel_size=1, stride=1, padding=0)
        self.phi = nn.Conv2d(g_channels, inter_channels, kernel_size=1, stride=1, padding=0)
        self.psi = nn.Conv2d(inter_channels, 1, kernel_size=1, stride=1, padding=0)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x, g):
        theta_x = self.theta(x)
        phi_g = self.phi(g)
        f = torch.relu(theta_x + phi_g)
        psi_f = self.psi(f)
        attention = self.sigmoid(psi_f)
        return x * attention


class ConvBlock(nn.Module):
    def __init__(self, in_channels, out_channels, use_batchnorm=True, activation='relu'):
        super(ConvBlock, self).__init__()
        self.activation = activation
        layers = [
            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.ReLU(inplace=True) if activation == 'relu' else nn.Identity(),
            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.ReLU(inplace=True) if activation == 'relu' else nn.Identity(),
        ]
        if use_batchnorm:
            layers.insert(2, nn.BatchNorm2d(out_channels))  # Add BatchNorm2d after first Conv2d
        self.block = nn.Sequential(*layers)
        if activation == 'tanh':
            self.final_activation = nn.Tanh()
        elif activation == 'sigmoid':
            self.final_activation = nn.Sigmoid()
        else:
            self.final_activation = nn.Identity()

    def forward(self, x):
        x = self.block(x)
        return self.final_activation(x)



# Encoder Block with Debugging and Adjustable Stride/Padding
class EncoderBlock(nn.Module):
    def __init__(self, in_channels, out_channels, use_attention=False, stride=2, padding=0, debug=False):
        """
        Args:
            in_channels (int): Number of input channels.
            out_channels (int): Number of output channels.
            use_attention (bool): Whether to use attention in the block.
            stride (int): Stride for the pooling operation (default is 2).
            padding (int): Padding for the pooling operation (default is 0).
            debug (bool): Whether to print shape information during forward pass.
        """
        super(EncoderBlock, self).__init__()
        self.conv = ConvBlock(in_channels, out_channels)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=stride, padding=padding)
        self.use_attention = use_attention
        self.debug = debug

        if self.use_attention:
            self.attention = AttentionBlock(out_channels, out_channels, out_channels)

    def forward(self, x):
        if self.debug:
            print(f"Input to EncoderBlock: {x.shape}")
        features = self.conv(x)
        if self.debug:
            print(f"After ConvBlock: {features.shape}")
        if self.use_attention:
            features = self.attention(features, features)  # Self-attention
            if self.debug:
                print(f"After AttentionBlock: {features.shape}")
        downsampled = self.pool(features)
        if self.debug:
            print(f"After Pooling: {downsampled.shape}")
        return features, downsampled


# Decoder Block
class DecoderBlock(nn.Module):
    def __init__(self, in_channels, out_channels, use_attention=False, debug=False):
        super(DecoderBlock, self).__init__()
        self.upconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)
        self.conv = ConvBlock(out_channels * 2, out_channels)
        self.use_attention = use_attention
        self.debug = debug

        if self.use_attention:
            # Ensure `g_channels` matches `out_channels`
            self.attention = AttentionBlock(out_channels, out_channels, out_channels)

    def forward(self, x, skip):
        x = self.upconv(x)
        if self.debug:
            print("Decoder Input Shape:", x.shape)
            print("Skip Connection Shape (Before Attention):", skip.shape)
        if self.use_attention:
            skip = self.attention(skip, x)
            if self.debug:
                print("Skip Connection Shape (After Attention):", skip.shape)
        x = torch.cat([x, skip], dim=1)
        x = self.conv(x)
        return x


class AttentionUNet(nn.Module):
    def __init__(self, in_channels=1, out_channels=1, use_attention=True, debug=False):
        super(AttentionUNet, self).__init__()
        self.debug = debug
        # Encoder
        self.enc1 = EncoderBlock(in_channels, 16)
        self.enc2 = EncoderBlock(16, 32)
        self.enc3 = EncoderBlock(32, 64)
        self.enc4 = EncoderBlock(64, 128)

        # Bottleneck
        self.bottleneck = ConvBlock(128, 256)

        # Decoder
        self.dec4 = DecoderBlock(256, 128, use_attention=use_attention, debug=debug)
        self.dec3 = DecoderBlock(128, 64, use_attention=use_attention, debug=debug)
        self.dec2 = DecoderBlock(64, 32, use_attention=use_attention, debug=debug)
        self.dec1 = DecoderBlock(32, 16, use_attention=False, debug=debug)

        # Final Output
        self.final_conv = nn.Conv2d(16, out_channels, kernel_size=1)

    def forward(self, x):
        if self.debug:
            print("input:", x.shape)
        # Encoder
        enc1, down1 = self.enc1(x)
        if self.debug:
            print("Encoder 1 Output Shape:", enc1.shape, "Down 1 Shape:", down1.shape)

        enc2, down2 = self.enc2(down1)
        if self.debug:
            print("Encoder 2 Output Shape:", enc2.shape, "Down 2 Shape:", down2.shape)

        enc3, down3 = self.enc3(down2)
        if self.debug:
            print("Encoder 3 Output Shape:", enc3.shape, "Down 3 Shape:", down3.shape)

        enc4, down4 = self.enc4(down3)
        if self.debug:
            print("Encoder 4 Output Shape:", enc4.shape, "Down 4 Shape:", down4.shape)

        # Bottleneck
        bottleneck = self.bottleneck(down4)
        if self.debug:
            print("Bottleneck Output Shape:", bottleneck.shape)

        # Decoder
        dec4 = self.dec4(bottleneck, enc4)
        if self.debug:
            print("Decoder 4 Output Shape:", dec4.shape)

        dec3 = self.dec3(dec4, enc3)
        if self.debug:
            print("Decoder 3 Output Shape:", dec3.shape)

        dec2 = self.dec2(dec3, enc2)
        if self.debug:
            print("Decoder 2 Output Shape:", dec2.shape)

        dec1 = self.dec1(dec2, enc1)
        if self.debug:
            print("Decoder 1 Output Shape:", dec1.shape)

        # Output
        out = self.final_conv(dec1)
        if self.debug:
            print("Final Output Shape:", out.shape)
        return out

"""## 2: GAN"""

class PatchGANDiscriminator(nn.Module):
    """
    PatchGAN Discriminator with optional FC layers after the final convolution.
    """

    def __init__(self, in_channels=2, base_channels=32, stride=[2, 2, 2, 2, 2, 2], padding=[0, 0, 0, 0, 0, 0], use_fc=False, global_pooling=False, debug=False):
        """
        Args:
            in_channels (int): Number of input channels (e.g., noisy + clean/generated = 2).
            base_channels (int): Number of base channels for the first encoder block.
            stride (list): List of strides for encoder blocks.
            padding (list): List of paddings for encoder blocks.
            use_fc (bool): Use fully connected layers after final convolution.
            global_pooling (bool): Apply global average pooling before FC.
            debug (bool): Enable debug prints.
        """
        super(PatchGANDiscriminator, self).__init__()
        self.debug = debug
        self.use_fc = use_fc
        self.global_pooling = global_pooling

        # Encoder layers
        self.enc1 = EncoderBlock(in_channels, base_channels, use_attention=True, stride=stride[0], padding=padding[0], debug=debug)
        self.enc2 = EncoderBlock(base_channels, base_channels * 2, use_attention=False, stride=stride[1], padding=padding[1], debug=debug)
        # self.enc3 = EncoderBlock(base_channels * 2, base_channels * 4, use_attention=True, stride=stride[2], padding=padding[2], debug=debug)
        # self.enc4 = EncoderBlock(base_channels * 4, base_channels * 8, use_attention=False, stride=stride[3], padding=padding[3], debug=debug)

        # Final convolution
        self.final_conv = nn.Conv2d(base_channels * 2, 1, kernel_size=2, stride=stride[5], padding=padding[5])

        # Fully connected layers
        if self.use_fc:
            self.fc_dim = 12 * 12  # Dimensions of the flattened output
            self.fc = nn.Sequential(
                # nn.Linear(base_channels * 8 * (22 * 22), self.fc_dim),  # Input: flattened size
                nn.Linear(base_channels * 2, self.fc_dim),  # Input: flattened size
                nn.Tanh(),  # Activation function
                nn.Linear(self.fc_dim, self.fc_dim),  # Output size
                nn.Tanh()
            )

    def forward(self, x, y):
        """
        Forward pass.
        Args:
            x (Tensor): Noisy input image.
            y (Tensor): Clean/generated image.
        Returns:
            Tensor: Patch-based real/fake scores.
        """
        # Concatenate inputs
        combined = torch.cat([x, y], dim=1)  # Shape: (B, 2, H, W)
        if self.debug:
            print(f"Input to PatchGANDiscriminator: {combined.shape}")

        # Encoder forward pass
        features, downsampled = self.enc1(combined)
        features, downsampled = self.enc2(downsampled)
        # features, downsampled = self.enc3(downsampled)
        # features, downsampled = self.enc4(downsampled)

        # Final convolution
        out = self.final_conv(features)  # Shape: (B, 1, H', W')
        if self.debug:
            print(f"Output of final_conv: {out.shape}")

        if self.use_fc:
            batch_size, channels, height, width = features.shape
            # Apply global pooling if enabled
            if self.global_pooling:
                if self.debug:
                   print(f"input of FC before global avg: {batch_size}, {channels}, {height}, {width}")
                pooled_features = torch.mean(features, dim=[2, 3])  # Global average pooling
                flattened = pooled_features.view(batch_size, -1)  # Flatten pooled features
                if self.debug:
                    print(f"input of FC after global avg: {flattened.shape}")
            else:
                flattened = features.view(batch_size, -1)  # Flatten directly without pooling

            fc_out = self.fc(flattened)  # Pass through FC layers
            if self.debug:
                    print(f"after  FC: {fc_out.shape}")
            out = fc_out.view(batch_size, 1, height, width)  # Reshape to patch size
            if self.debug:
                print(f"Output after FC layers (with global pooling): {out.shape}")


        return out

import torch
import torch.nn as nn
import torch.optim as optim
from tqdm import tqdm
import matplotlib.pyplot as plt
from skimage.metrics import structural_similarity as compare_ssim

pip install --upgrade torchmetrics

"""# Training

## Task1: Denoising Low Gaussian Noise

### ATTUNET
"""

import torch
import matplotlib.pyplot as plt
from torchmetrics.functional import structural_similarity_index_measure as ssim
from torchmetrics.functional import peak_signal_noise_ratio as psnr

# Function to visualize images
def visualize_images(clean_image, noisy_image):
    plt.figure(figsize=(10, 5))

    plt.subplot(1, 2, 1)
    plt.title("Clean Image")
    plt.imshow(clean_image.squeeze(), cmap='gray')

    plt.subplot(1, 2, 2)
    plt.title("Noisy Image")
    plt.imshow(noisy_image.squeeze(), cmap='gray')

    plt.show()

# Extract a batch from the train loader
for noisy_images, clean_images in train_loaders['low_gaussian_noise']:
    # Select the first sample from the batch
    clean_image_sample = clean_images[0].cpu().numpy().squeeze()  # Ground truth
    noisy_image_sample = noisy_images[0].cpu().numpy().squeeze()  # Noisy version

    # Visualize the clean and noisy images
    visualize_images(clean_image_sample, noisy_image_sample)

    # Compute SSIM and PSNR
    clean_image_tensor = clean_images[0].unsqueeze(0).to(dtype=torch.float32)  # Add batch dimension
    noisy_image_tensor = noisy_images[0].unsqueeze(0).to(dtype=torch.float32)  # Add batch dimension

    # Ground on ground
    clean_to_self_ssim = ssim(clean_image_tensor, clean_image_tensor, data_range=2.0)
    clean_to_self_psnr = psnr(clean_image_tensor, clean_image_tensor, data_range=2.0)

    # Ground on noise
    clean_to_noisy_ssim = ssim(clean_image_tensor, noisy_image_tensor, data_range=2.0)
    clean_to_noisy_psnr = psnr(clean_image_tensor, noisy_image_tensor, data_range=2.0)

    # Print results
    print("SSIM and PSNR Results:")
    print(f"Clean Image with Itself - SSIM: {clean_to_self_ssim:.4f}, PSNR: {clean_to_self_psnr:.4f}")
    print(f"Clean Image with Noisy Version - SSIM: {clean_to_noisy_ssim:.4f}, PSNR: {clean_to_noisy_psnr:.4f}")

    break  # Only process one batch

import torch
import matplotlib.pyplot as plt
from torchmetrics.functional import structural_similarity_index_measure as ssim
from torchmetrics.functional import peak_signal_noise_ratio as psnr
from tqdm import tqdm


class Trainer:
    def __init__(self, model, train_loader, val_loader, optimizer, criterion, scheduler=None, device='cuda'):
        self.model = model.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.optimizer = optimizer
        self.criterion = criterion
        self.scheduler = scheduler
        self.device = device

        # Logging
        self.train_history = {'loss': [], 'psnr': [], 'ssim': []}
        self.val_history = {'loss': [], 'psnr': [], 'ssim': []}

        # Best Scores
        self.best_val_loss = float('inf')
        self.best_val_psnr = 0
        self.best_val_ssim = 0

    def compute_metrics(self, clean_images, outputs):
        """Compute PSNR and SSIM for a batch."""
        psnr_score = psnr(outputs, clean_images, data_range=2.0).item()
        ssim_score = ssim(outputs, clean_images, data_range=2.0).item()
        return psnr_score, ssim_score

    def train_epoch(self):
        self.model.train()
        total_loss, total_psnr, total_ssim, num_batches = 0, 0, 0, 0

        for noisy_images, clean_images in tqdm(self.train_loader, desc="Training"):
            noisy_images = noisy_images.to(self.device, dtype=torch.float32)
            clean_images = clean_images.to(self.device, dtype=torch.float32)

            # Forward
            outputs = self.model(noisy_images)
            loss = self.criterion(outputs, clean_images)

            # Backward
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

            # Metrics
            psnr_score, ssim_score = self.compute_metrics(clean_images, outputs)
            total_loss += loss.item()
            total_psnr += psnr_score
            total_ssim += ssim_score
            num_batches += 1

        return total_loss / num_batches, total_psnr / num_batches, total_ssim / num_batches

    def validate_epoch(self):
        self.model.eval()
        total_loss, total_psnr, total_ssim, num_batches = 0, 0, 0, 0

        with torch.no_grad():
            for noisy_images, clean_images in tqdm(self.val_loader, desc="Validating"):
                noisy_images = noisy_images.to(self.device, dtype=torch.float32)
                clean_images = clean_images.to(self.device, dtype=torch.float32)

                # Forward
                outputs = self.model(noisy_images)
                loss = self.criterion(outputs, clean_images)

                # Metrics
                psnr_score, ssim_score = self.compute_metrics(clean_images, outputs)
                total_loss += loss.item()
                total_psnr += psnr_score
                total_ssim += ssim_score
                num_batches += 1

        return total_loss / num_batches, total_psnr / num_batches, total_ssim / num_batches

    def plot_metrics(self):
        """Plot and save training and validation metrics."""
        for metric in ['loss', 'psnr', 'ssim']:
            plt.figure(figsize=(10, 5))
            plt.plot(self.train_history[metric], label=f"Train {metric.capitalize()}")
            plt.plot(self.val_history[metric], label=f"Val {metric.capitalize()}")
            plt.xlabel("Epochs")
            plt.ylabel(metric.capitalize())
            plt.title(f"Training and Validation {metric.capitalize()}")
            plt.legend()
            plt.savefig(f"{metric}_plot.png")
            plt.close()

    def fit(self, num_epochs, save_path='best_model.pth', early_stop_patience=5):
        early_stop_count = 0

        for epoch in range(num_epochs):
            print(f"\nEpoch {epoch + 1}/{num_epochs}")

            # Training
            train_loss, train_psnr, train_ssim = self.train_epoch()
            self.train_history['loss'].append(train_loss)
            self.train_history['psnr'].append(train_psnr)
            self.train_history['ssim'].append(train_ssim)

            # Validation
            val_loss, val_psnr, val_ssim = self.validate_epoch()
            self.val_history['loss'].append(val_loss)
            self.val_history['psnr'].append(val_psnr)
            self.val_history['ssim'].append(val_ssim)

            # Scheduler Step
            if self.scheduler:
                self.scheduler.step(val_loss)

            # Logging
            print(f"Train Loss: {train_loss:.4f}, PSNR: {train_psnr:.4f}, SSIM: {train_ssim:.4f}")
            print(f"Val Loss: {val_loss:.4f}, PSNR: {val_psnr:.4f}, SSIM: {val_ssim:.4f}")

            # Save Best Model
            if val_loss < self.best_val_loss:
                print(f"Validation loss improved from {self.best_val_loss:.4f} to {val_loss:.4f}. Saving model...")
                torch.save(self.model.state_dict(), save_path)
                self.best_val_loss = val_loss
                self.best_val_psnr = val_psnr
                self.best_val_ssim = val_ssim
                early_stop_count = 0
            else:
                early_stop_count += 1

            # Early Stopping
            if early_stop_count >= early_stop_patience:
                print("Early stopping triggered.")
                break

        self.plot_metrics()

# Configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Step 1: Initialize the model with debugging enabled for testing
debug_model = AttentionUNet(in_channels=1, out_channels=1, debug=True).to(device)

# Test with a single dummy input
test_input = torch.randn(2, 1, 48, 48).to(device)  # Batch size 2, single-channel, 48x48
test_output = debug_model(test_input)
print("Test Output Shape with Debugging:", test_output.shape)

# Configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Initialize Model
model = AttentionUNet(in_channels=1, out_channels=1).to(device)

# Define Loss, Optimizer, and Scheduler
criterion = nn.MSELoss()
optimizer = optim.Adam(model.parameters(), lr=1e-3)
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)

# Print Shapes of a Batch from the Train Loader
for noisy_images, clean_images in train_loaders['low_gaussian_noise']:
    print("Noisy Image Shape:", noisy_images.shape)
    print("Clean Image Shape:", clean_images.shape)
    break  # Only print shapes for the first batch

# Helper Function: Get Model Save Path
def get_model_save_path(base_path, filename="best_model.pth"):
    """
    Get the save path for the model in the same directory as the dataset.
    Args:
        base_path (str): Path to the dataset directory.
        filename (str): Name of the model file to save.
    Returns:
        str: Full path to save the model.
    """
    save_dir = os.path.join(base_path, "models")
    os.makedirs(save_dir, exist_ok=True)
    return os.path.join(save_dir, filename)

# Define Dataset Base Path and Model Save Path
dataset_base_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data"
save_path = get_model_save_path(dataset_base_path, filename="attention_unet_best_model.pth")

# Test the Model with a Dummy Input
print("\nTesting Model with Dummy Input:")
test_input = torch.randn(2, 1, 48, 48).to(device)  # Batch size 2, single-channel, 48x48
test_output = model(test_input)
print("Test Output Shape:", test_output.shape)

# Initialize Trainer
trainer = Trainer(
    model=model,
    train_loader=train_loaders['low_gaussian_noise'],
    val_loader=val_loaders['low_gaussian_noise'],
    optimizer=optimizer,
    criterion=criterion,
    scheduler=scheduler,
    device=device
)

# Train the Model
print("\nStarting Training:")
trainer.fit(num_epochs=20, save_path=save_path)

print(f"\nTraining completed. Model saved at: {save_path}")

import matplotlib.pyplot as plt

# Function to plot metrics
def plot_training_history(trainer):
    metrics = ['loss', 'psnr', 'ssim']
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))

    for idx, metric in enumerate(metrics):
        axes[idx].plot(trainer.train_history[metric], label=f"Train {metric.capitalize()}")
        axes[idx].plot(trainer.val_history[metric], label=f"Val {metric.capitalize()}")
        axes[idx].set_title(f"Training and Validation {metric.capitalize()}")
        axes[idx].set_xlabel("Epochs")
        axes[idx].set_ylabel(metric.capitalize())
        axes[idx].legend()

    plt.tight_layout()
    plt.savefig("training_history.png")
    plt.show()

# Call the function after training
plot_training_history(trainer)

def evaluate_on_test_set(model, test_loader, criterion, device='cuda'):
    """
    Evaluate the model on the test set and compute average metrics.
    Args:
        model: Trained model.
        test_loader: DataLoader for the test dataset.
        criterion: Loss function.
        device: Device (CPU or GPU).

    Returns:
        Average test loss, PSNR, and SSIM.
    """
    model.eval()
    total_loss, total_psnr, total_ssim, num_batches = 0, 0, 0, 0

    with torch.no_grad():
        for noisy_images, clean_images in tqdm(test_loader, desc="Testing"):
            noisy_images = noisy_images.to(device, dtype=torch.float32)
            clean_images = clean_images.to(device, dtype=torch.float32)

            # Forward pass
            outputs = model(noisy_images)
            loss = criterion(outputs, clean_images)

            # Compute metrics
            psnr_score = psnr(outputs, clean_images, data_range=2.0).item()
            ssim_score = ssim(outputs, clean_images, data_range=2.0).item()

            total_loss += loss.item()
            total_psnr += psnr_score
            total_ssim += ssim_score
            num_batches += 1

    # Calculate averages
    avg_loss = total_loss / num_batches
    avg_psnr = total_psnr / num_batches
    avg_ssim = total_ssim / num_batches

    return avg_loss, avg_psnr, avg_ssim

test_loss, test_psnr, test_ssim = evaluate_on_test_set(model, test_loaders['low_gaussian_noise'], criterion, device)
print(f"\nTest Set Metrics:\nLoss: {test_loss:.4f}, PSNR: {test_psnr:.4f}, SSIM: {test_ssim:.4f}")

def visualize_predictions(model, loader, device='cuda', num_samples=5):
    """
    Visualize model predictions alongside metrics for a subset of samples.

    Args:
        model: Trained model.
        loader: DataLoader for the test dataset.
        device: Device (CPU or GPU).
        num_samples: Number of samples to visualize.
    """
    model.eval()
    with torch.no_grad():
        for noisy_images, clean_images in loader:
            noisy_images = noisy_images.to(device, dtype=torch.float32)
            clean_images = clean_images.to(device, dtype=torch.float32)

            # Get model predictions
            denoised_images = model(noisy_images)

            # Select the first `num_samples`
            noisy_images = noisy_images[:num_samples].cpu()
            clean_images = clean_images[:num_samples].cpu()
            denoised_images = denoised_images[:num_samples].cpu()

            # Plot each sample
            num_cols = 3
            fig, axes = plt.subplots(num_samples, num_cols, figsize=(15, 5 * num_samples))
            for i in range(num_samples):
                # Compute metrics
                psnr_noisy = psnr(noisy_images[i].unsqueeze(0), clean_images[i].unsqueeze(0), data_range=2.0).item()
                ssim_noisy = ssim(noisy_images[i].unsqueeze(0), clean_images[i].unsqueeze(0), data_range=2.0).item()
                psnr_denoised = psnr(denoised_images[i].unsqueeze(0), clean_images[i].unsqueeze(0), data_range=2.0).item()
                ssim_denoised = ssim(denoised_images[i].unsqueeze(0), clean_images[i].unsqueeze(0), data_range=2.0).item()

                # Plot ground truth
                axes[i, 0].imshow(clean_images[i][0], cmap='gray')
                axes[i, 0].set_title("Ground Truth")
                axes[i, 0].axis('off')

                # Plot noisy image
                axes[i, 1].imshow(noisy_images[i][0], cmap='gray')
                axes[i, 1].set_title(f"Noisy\nPSNR: {psnr_noisy:.2f}, SSIM: {ssim_noisy:.2f}")
                axes[i, 1].axis('off')

                # Plot denoised image
                axes[i, 2].imshow(denoised_images[i][0], cmap='gray')
                axes[i, 2].set_title(f"Denoised\nPSNR: {psnr_denoised:.2f}, SSIM: {ssim_denoised:.2f}")
                axes[i, 2].axis('off')

            plt.tight_layout()
            plt.savefig("prediction_visualization.png")
            plt.show()
            break  # Only process one batch

# Example usage
visualize_predictions(model, test_loaders['low_gaussian_noise'], device=device, num_samples=5)

"""### GAN

#### trainer
"""

from tqdm import tqdm
import torch
import torch.nn.functional as F
from torchmetrics.functional import structural_similarity_index_measure as ssim
from torchmetrics.functional import peak_signal_noise_ratio as psnr
import json

class GANTrainer:
    def __init__(self, generator, discriminator, train_loader, val_loader, gen_optimizer, disc_optimizer, gen_criterion, device='cuda'):
        """
        Initialize the GAN trainer.

        Args:
            generator (nn.Module): The generator model.
            discriminator (nn.Module): The discriminator model.
            train_loader (DataLoader): Training dataset loader.
            val_loader (DataLoader): Validation dataset loader.
            gen_optimizer (Optimizer): Optimizer for the generator.
            disc_optimizer (Optimizer): Optimizer for the discriminator.
            gen_criterion (Loss): Loss function for the generator.
            device (str): Device to use ('cuda' or 'cpu').
        """
        self.generator = generator.to(device)
        self.discriminator = discriminator.to(device)
        self.train_loader = train_loader
        self.val_loader = val_loader
        self.gen_optimizer = gen_optimizer
        self.disc_optimizer = disc_optimizer
        self.gen_criterion = gen_criterion
        self.device = device

        # Logging
        self.train_history = {'gen_loss': [], 'disc_loss': [], 'psnr': [], 'ssim': []}
        self.val_history = {'gen_loss': [], 'disc_loss': [], 'psnr': [], 'ssim': []}

        # Best model tracking
        self.best_val_loss = float('inf')

    def compute_metrics(self, clean_images, generated_images):
        """Compute PSNR and SSIM for a batch."""
        psnr_score = psnr(generated_images, clean_images, data_range=1.0).item()
        ssim_score = ssim(generated_images, clean_images, data_range=1.0).item()
        return psnr_score, ssim_score

    def train_epoch(self):
        """Train the GAN for one epoch."""
        self.generator.train()
        self.discriminator.train()
        total_gen_loss, total_disc_loss, total_psnr, total_ssim, num_batches = 0, 0, 0, 0, 0

        for noisy_images, clean_images in tqdm(self.train_loader, desc="Training"):
            noisy_images = noisy_images.to(self.device, dtype=torch.float32)
            clean_images = clean_images.to(self.device, dtype=torch.float32)

            ### Train Discriminator ###
            self.disc_optimizer.zero_grad()

            # Generate fake images
            fake_images = self.generator(noisy_images)

            # Discriminator predictions
            real_preds = self.discriminator(noisy_images, clean_images)  # Output: Bx1x8x8
            fake_preds = self.discriminator(noisy_images, fake_images.detach())  # Output: Bx1x8x8

            # Targets must match discriminator output shape
            real_targets = torch.ones_like(real_preds, device=self.device)
            fake_targets = torch.zeros_like(fake_preds, device=self.device)

            # Compute discriminator loss
            real_loss = F.binary_cross_entropy_with_logits(real_preds, real_targets)
            fake_loss = F.binary_cross_entropy_with_logits(fake_preds, fake_targets)
            disc_loss = (real_loss + fake_loss) / 2
            disc_loss.backward()
            self.disc_optimizer.step()

            ### Train Generator ###
            self.gen_optimizer.zero_grad()

            # Recompute fake images and discriminator output
            fake_preds = self.discriminator(noisy_images, fake_images)

            # Generator loss: L2 loss + adversarial loss
            l2_loss = self.gen_criterion(fake_images, clean_images)
            adversarial_loss = F.binary_cross_entropy_with_logits(fake_preds, real_targets)  # Use real targets
            gen_loss = l2_loss + 0.001 * adversarial_loss
            gen_loss.backward()
            self.gen_optimizer.step()

            # Compute metrics
            psnr_score, ssim_score = self.compute_metrics(clean_images, fake_images)
            total_gen_loss += gen_loss.item()
            total_disc_loss += disc_loss.item()
            total_psnr += psnr_score
            total_ssim += ssim_score
            num_batches += 1

        return total_gen_loss / num_batches, total_disc_loss / num_batches, total_psnr / num_batches, total_ssim / num_batches

    def validate_epoch(self):
        """Validate the GAN for one epoch."""
        self.generator.eval()
        self.discriminator.eval()
        total_gen_loss, total_disc_loss, total_psnr, total_ssim, num_batches = 0, 0, 0, 0, 0

        with torch.no_grad():
            for noisy_images, clean_images in tqdm(self.val_loader, desc="Validating"):
                noisy_images = noisy_images.to(self.device, dtype=torch.float32)
                clean_images = clean_images.to(self.device, dtype=torch.float32)

                # Generate fake images
                fake_images = self.generator(noisy_images)

                # Discriminator predictions
                real_preds = self.discriminator(noisy_images, clean_images)
                fake_preds = self.discriminator(noisy_images, fake_images)

                real_targets = torch.full_like(real_preds, 0.9, device=self.device)  # Smoothed real labels
                fake_targets = torch.full_like(fake_preds, 0.1, device=self.device)  # Smoothed fake labels


                # Compute losses
                real_loss = F.binary_cross_entropy_with_logits(real_preds, real_targets)
                fake_loss = F.binary_cross_entropy_with_logits(fake_preds, fake_targets)
                disc_loss = (real_loss + fake_loss) / 2

                l2_loss = self.gen_criterion(fake_images, clean_images)
                adversarial_loss = F.binary_cross_entropy_with_logits(fake_preds, real_targets)
                gen_loss = l2_loss + 0.001 * adversarial_loss

                # Compute metrics
                psnr_score, ssim_score = self.compute_metrics(clean_images, fake_images)
                total_gen_loss += gen_loss.item()
                total_disc_loss += disc_loss.item()
                total_psnr += psnr_score
                total_ssim += ssim_score
                num_batches += 1

        return total_gen_loss / num_batches, total_disc_loss / num_batches, total_psnr / num_batches, total_ssim / num_batches

    def fit(self, num_epochs, gen_save_path='generator.pth', disc_save_path='discriminator.pth', history_path='final_training_history.json'):
        """
        Train the GAN model and save metrics at the end of training.
        Args:
            num_epochs (int): Number of epochs.
            save_path (str): Path to save the generator model.
            history_path (str): Path to save the final comprehensive training history.
        """
        for epoch in range(num_epochs):
            print(f"\nEpoch {epoch + 1}/{num_epochs}")

            # Training
            train_gen_loss, train_disc_loss, train_psnr, train_ssim = self.train_epoch()
            self.train_history['gen_loss'].append(train_gen_loss)
            self.train_history['disc_loss'].append(train_disc_loss)
            self.train_history['psnr'].append(train_psnr)
            self.train_history['ssim'].append(train_ssim)

            # Validation
            val_gen_loss, val_disc_loss, val_psnr, val_ssim = self.validate_epoch()
            self.val_history['gen_loss'].append(val_gen_loss)
            self.val_history['disc_loss'].append(val_disc_loss)
            self.val_history['psnr'].append(val_psnr)
            self.val_history['ssim'].append(val_ssim)

            # Logging
            print(f"Train Gen Loss: {train_gen_loss:.4f}, Train Disc Loss: {train_disc_loss:.4f}, PSNR: {train_psnr:.4f}, SSIM: {train_ssim:.4f}")
            print(f"Val Gen Loss: {val_gen_loss:.4f}, Val Disc Loss: {val_disc_loss:.4f}, PSNR: {val_psnr:.4f}, SSIM: {val_ssim:.4f}")

            # Save the best generator model
            if val_gen_loss < self.best_val_loss:
                print(f"Validation generator loss improved. Saving models to {gen_save_path} and {disc_save_path}...")
                torch.save(self.generator.state_dict(), gen_save_path)
                torch.save(self.discriminator.state_dict(), disc_save_path)
                self.best_val_loss = val_gen_loss

        # Save all metrics at the end of training
        self.save_final_metrics(history_path)

    def save_final_metrics(self, path):
        """
        Save the final training and validation history to a file.
        Args:
            path (str): Path to save the history as a JSON file.
        """
        history = {
            'train_history': self.train_history,
            'val_history': self.val_history,
        }
        with open(path, 'w') as f:
            json.dump(history, f, indent=4)
        print(f"Final training and validation history saved to {path}")

    def load_history(self, path):
        """
        Load training and validation history from a JSON file.
        Args:
            path (str): Path to the history JSON file.
        """
        with open(path, 'r') as f:
            history = json.load(f)
        self.train_history = history['train_history']
        self.val_history = history['val_history']
        print(f"History loaded from {path}")

"""#### test, configuration, training

##### V1
"""

# Configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Initialize Models
discriminator = PatchGANDiscriminator(in_channels=2, base_channels=32, stride=2, padding=1, debug=True).to(device)

# Create dummy inputs
noisy_input = torch.randn(2, 1, 48, 48).to(device)  # Noisy image
generated_input = torch.randn(2, 1, 48, 48).to(device)  # Generated image

# Test the discriminator
print("\nTesting PatchGANDiscriminator:")
output = discriminator(noisy_input, generated_input)

"""##### V2"""

# Configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Initialize Models
discriminator = PatchGANDiscriminator(in_channels=2, base_channels=32, stride=[2, 1, 1, 1, 1, 1], padding=[1, 0, 0, 0, 0, 0], debug=True).to(device)

# Create dummy inputs
noisy_input = torch.randn(2, 1, 48, 48).to(device)  # Noisy image
generated_input = torch.randn(2, 1, 48, 48).to(device)  # Generated image

# Test the discriminator
print("\nTesting PatchGANDiscriminator:")
output = discriminator(noisy_input, generated_input)

"""##### V3"""

# Configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Initialize Models
discriminator = PatchGANDiscriminator(in_channels=2, base_channels=32, stride=[2, 2, 1, 1, 1, 1], padding=[0, 0, 0, 0, 0, 0], use_fc=True, global_pooling=True, debug=True).to(device)

# Create dummy inputs
noisy_input = torch.randn(2, 1, 48, 48).to(device)  # Noisy image
generated_input = torch.randn(2, 1, 48, 48).to(device)  # Generated image

# Test the discriminator
print("\nTesting PatchGANDiscriminator:")
output = discriminator(noisy_input, generated_input)

"""##### V2"""

from torchsummary import summary

class PatchGANWrapper(nn.Module):
    """
    A wrapper to enable testing the PatchGAN Discriminator with torchsummary.
    It combines the noisy and generated inputs into a single tensor.
    """
    def __init__(self, discriminator):
        super(PatchGANWrapper, self).__init__()
        self.discriminator = discriminator

    def forward(self, combined_input):
        # Split the combined input into two parts
        noisy_input, generated_input = torch.chunk(combined_input, chunks=2, dim=1)
        return self.discriminator(noisy_input, generated_input)


# Configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Initialize the PatchGAN Discriminator and its wrapper
discriminator = PatchGANDiscriminator(in_channels=2, base_channels=32, stride=[2, 1, 1, 1, 1, 1], padding=[1, 0, 0, 0, 0, 0]).to(device)
discriminator_wrapper = PatchGANWrapper(discriminator).to(device)

# Test Input Shapes
combined_input = torch.randn(1, 2, 48, 48).to(device)  # Combine noisy and generated inputs

# Display Model Summary
print("\nPatchGAN Discriminator Summary:")
summary(discriminator_wrapper, input_size=combined_input.shape[1:])

"""##### V3"""

from torchsummary import summary

class PatchGANWrapper(nn.Module):
    """
    A wrapper to enable testing the PatchGAN Discriminator with torchsummary.
    It combines the noisy and generated inputs into a single tensor.
    """
    def __init__(self, discriminator):
        super(PatchGANWrapper, self).__init__()
        self.discriminator = discriminator

    def forward(self, combined_input):
        # Split the combined input into two parts
        noisy_input, generated_input = torch.chunk(combined_input, chunks=2, dim=1)
        return self.discriminator(noisy_input, generated_input)


# Configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Initialize the PatchGAN Discriminator and its wrapper
discriminator = PatchGANDiscriminator(in_channels=2, base_channels=32, stride=[2, 1, 1, 1, 1, 1], padding=[0, 0, 0, 0, 0, 0], use_fc=True, global_pooling=True).to(device)
discriminator_wrapper = PatchGANWrapper(discriminator).to(device)

# Test Input Shapes
combined_input = torch.randn(1, 2, 48, 48).to(device)  # Combine noisy and generated inputs

# Display Model Summary
print("\nPatchGAN Discriminator Summary:")
summary(discriminator_wrapper, input_size=combined_input.shape[1:])

# Configuration
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Initialize Models
generator = AttentionUNet(in_channels=1, out_channels=1, use_attention=True).to(device)
discriminator = PatchGANDiscriminator(in_channels=2, base_channels=32, stride=[2, 1, 1, 1, 1, 1], padding=[0, 0, 0, 0, 0, 0]).to(device)

# Optimizers
gen_optimizer = optim.Adam(generator.parameters(), lr=1e-4, betas=(0.5, 0.999))
disc_optimizer = optim.Adam(discriminator.parameters(), lr=1e-4, betas=(0.5, 0.999))

# Loss Function for the Generator
gen_criterion = nn.MSELoss()

# Train and validation DataLoaders (assume they are already defined)
train_loader = train_loaders['low_gaussian_noise']
val_loader = val_loaders['low_gaussian_noise']

# Initialize GAN Trainer
gan_trainer = GANTrainer(
    generator=generator,
    discriminator=discriminator,
    train_loader=train_loader,
    val_loader=val_loader,
    gen_optimizer=gen_optimizer,
    disc_optimizer=disc_optimizer,
    gen_criterion=gen_criterion,
    device=device
)

# Paths to save the models and training history
gen_save_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/patch_gan_generator_v2.pth"
disc_save_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/patch_gan_discriminator_v2.pth"
history_save_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/patch_gan_training_history_v2.json"

# Train the GAN
gan_trainer.fit(
    num_epochs=20,
    gen_save_path=gen_save_path,
    disc_save_path=disc_save_path,
    history_path=history_save_path
)

"""##### V1"""

import matplotlib.pyplot as plt

def plot_gan_training_history(trainer, path='gan_training_history.png'):
    """
    Plot training and validation history for GAN.
    Args:
        trainer (GANTrainer): The GANTrainer object with training history.
    """
    metrics = ['gen_loss', 'disc_loss', 'psnr', 'ssim']
    titles = ['Generator Loss', 'Discriminator Loss', 'PSNR', 'SSIM']

    fig, axes = plt.subplots(1, 4, figsize=(24, 5))

    for idx, metric in enumerate(metrics):
        axes[idx].plot(trainer.train_history[metric], label=f"Train {titles[idx]}")
        axes[idx].plot(trainer.val_history[metric], label=f"Val {titles[idx]}")
        axes[idx].set_title(f"Training and Validation {titles[idx]}")
        axes[idx].set_xlabel("Epochs")
        axes[idx].set_ylabel(titles[idx])
        axes[idx].legend()

    plt.tight_layout()

    plt.savefig(path)
    plt.show()

plot_gan_training_history(gan_trainer)

"""##### V2"""

plot_gan_training_history(gan_trainer, 'gan_training_history_v2.png')

def evaluate_gan_on_test_set(generator, test_loader, criterion, device='cuda'):
    """
    Evaluate the GAN generator on the test set and compute average metrics.
    Args:
        generator: Trained generator model.
        test_loader: DataLoader for the test dataset.
        criterion: Loss function for the generator.
        device: Device (CPU or GPU).

    Returns:
        Average test loss, PSNR, and SSIM.
    """
    generator.eval()
    total_loss, total_psnr, total_ssim, num_batches = 0, 0, 0, 0

    with torch.no_grad():
        for noisy_images, clean_images in tqdm(test_loader, desc="Testing"):
            noisy_images = noisy_images.to(device, dtype=torch.float32)
            clean_images = clean_images.to(device, dtype=torch.float32)

            # Generate fake images
            generated_images = generator(noisy_images)
            loss = criterion(generated_images, clean_images)

            # Compute metrics
            psnr_score = psnr(generated_images, clean_images, data_range=1.0).item()
            ssim_score = ssim(generated_images, clean_images, data_range=1.0).item()

            total_loss += loss.item()
            total_psnr += psnr_score
            total_ssim += ssim_score
            num_batches += 1

    avg_loss = total_loss / num_batches
    avg_psnr = total_psnr / num_batches
    avg_ssim = total_ssim / num_batches

    return avg_loss, avg_psnr, avg_ssim

"""##### V1"""

# Example usage
test_loss, test_psnr, test_ssim = evaluate_gan_on_test_set(generator, test_loaders['low_gaussian_noise'], gen_criterion, device)
print(f"\nTest Set Metrics:\nLoss: {test_loss:.4f}, PSNR: {test_psnr:.4f}, SSIM: {test_ssim:.4f}")

"""##### V2"""

# Example usage
test_loss, test_psnr, test_ssim = evaluate_gan_on_test_set(generator, test_loaders['low_gaussian_noise'], gen_criterion, device)
print(f"\nTest Set Metrics:\nLoss: {test_loss:.4f}, PSNR: {test_psnr:.4f}, SSIM: {test_ssim:.4f}")

def visualize_gan_predictions(generator, loader, device='cuda', num_samples=5):
    """
    Visualize generator predictions alongside noisy and clean images.

    Args:
        generator: Trained generator model.
        loader: DataLoader for the test dataset.
        device: Device (CPU or GPU).
        num_samples: Number of samples to visualize.
    """
    generator.eval()
    with torch.no_grad():
        for noisy_images, clean_images in loader:
            noisy_images = noisy_images.to(device, dtype=torch.float32)
            clean_images = clean_images.to(device, dtype=torch.float32)

            # Generate fake images
            generated_images = generator(noisy_images)

            # Select the first `num_samples`
            noisy_images = noisy_images[:num_samples].cpu()
            clean_images = clean_images[:num_samples].cpu()
            generated_images = generated_images[:num_samples].cpu()

            # Plot each sample
            num_cols = 3
            fig, axes = plt.subplots(num_samples, num_cols, figsize=(15, 5 * num_samples))
            for i in range(num_samples):
                # Compute metrics
                psnr_noisy = psnr(noisy_images[i].unsqueeze(0), clean_images[i].unsqueeze(0), data_range=1.0).item()
                ssim_noisy = ssim(noisy_images[i].unsqueeze(0), clean_images[i].unsqueeze(0), data_range=1.0).item()
                psnr_generated = psnr(generated_images[i].unsqueeze(0), clean_images[i].unsqueeze(0), data_range=1.0).item()
                ssim_generated = ssim(generated_images[i].unsqueeze(0), clean_images[i].unsqueeze(0), data_range=1.0).item()

                # Plot ground truth
                axes[i, 0].imshow(clean_images[i][0], cmap='gray')
                axes[i, 0].set_title("Ground Truth")
                axes[i, 0].axis('off')

                # Plot noisy image
                axes[i, 1].imshow(noisy_images[i][0], cmap='gray')
                axes[i, 1].set_title(f"Noisy\nPSNR: {psnr_noisy:.2f}, SSIM: {ssim_noisy:.2f}")
                axes[i, 1].axis('off')

                # Plot generated image
                axes[i, 2].imshow(generated_images[i][0], cmap='gray')
                axes[i, 2].set_title(f"Generated\nPSNR: {psnr_generated:.2f}, SSIM: {ssim_generated:.2f}")
                axes[i, 2].axis('off')

            plt.tight_layout()
            plt.savefig("gan_prediction_visualization.png")
            plt.show()
            break  # Only process one batch

"""##### V1"""

# Example usage
visualize_gan_predictions(generator, test_loaders['low_gaussian_noise'], device=device, num_samples=5)

"""##### V2"""

# Example usage
visualize_gan_predictions(generator, test_loaders['low_gaussian_noise'], device=device, num_samples=5)

"""## Task 2: Denosing High Gaussian Noise

### AttentionUnet
"""

# Load Pretrained Model for High Gaussian Noise
model = AttentionUNet(in_channels=1, out_channels=1).to(device)

# Load weights from the previous task
low_noise_model_path = get_model_save_path(dataset_base_path, filename="attention_unet_best_model.pth")
model.load_state_dict(torch.load(low_noise_model_path))
print(f"Loaded pretrained weights from: {low_noise_model_path}")

# Visualize high Gaussian noise dataset
print("Visualizing High Gaussian Noise:")
visualize_noisy_clean(train_loaders['high_gaussian_noise'])

# Update optimizer and scheduler for high noise training
optimizer = optim.Adam(model.parameters(), lr=1e-4)  # Adjust learning rate if needed
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)

# Save path for high noise training
high_noise_model_path = get_model_save_path(dataset_base_path, filename="attention_unet_best_model_high_noise.pth")

# Initialize Trainer for high Gaussian noise
trainer = Trainer(
    model=model,
    train_loader=train_loaders['high_gaussian_noise'],
    val_loader=val_loaders['high_gaussian_noise'],
    optimizer=optimizer,
    criterion=criterion,
    scheduler=scheduler,
    device=device
)

# Train the model on high Gaussian noise
print("\nStarting Training for High Gaussian Noise:")
trainer.fit(num_epochs=20, save_path=high_noise_model_path)

print(f"\nTraining completed for High Gaussian Noise. Model saved at: {high_noise_model_path}")

# Call the function after training
plot_training_history(trainer)

# Evaluate the model on the high Gaussian noise test set
test_loss, test_psnr, test_ssim = evaluate_on_test_set(
    model,
    test_loaders['high_gaussian_noise'],
    criterion,
    device
)
print(f"\nHigh Gaussian Noise Test Set Metrics:\nLoss: {test_loss:.4f}, PSNR: {test_psnr:.4f}, SSIM: {test_ssim:.4f}")

# Visualize predictions for high Gaussian noise test set
visualize_predictions(model, test_loaders['high_gaussian_noise'], device=device, num_samples=5)

"""### GAN"""

# Load Pretrained Generator for High Gaussian Noise
high_noise_generator = AttentionUNet().to(device)
low_noise_gen_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/patch_gan_generator_v2.pth"
high_noise_generator.load_state_dict(torch.load(low_noise_gen_path))
print(f"Loaded pretrained generator weights from: {low_noise_gen_path}")

# Load Pretrained Discriminator for High Gaussian Noise
high_noise_discriminator = PatchGANDiscriminator(in_channels=2, base_channels=32, stride=[2, 1, 1, 1, 1, 1], padding=[1, 0, 0, 0, 0, 0]).to(device)
low_noise_disc_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/patch_gan_discriminator_v2.pth"
high_noise_discriminator.load_state_dict(torch.load(low_noise_disc_path))
print(f"Loaded pretrained discriminator weights from: {low_noise_disc_path}")

# Visualize high Gaussian noise dataset
print("Visualizing High Gaussian Noise:")
visualize_noisy_clean(train_loaders['high_gaussian_noise'])

"""##### V1"""

# Define optimizer and loss function for the new task
gen_optimizer = torch.optim.Adam(high_noise_generator.parameters(), lr=1e-4)
disc_optimizer = torch.optim.Adam(high_noise_discriminator.parameters(), lr=1e-4)
gen_criterion = torch.nn.MSELoss()  # Adjust loss function if needed

# Define save paths for the new task
high_noise_gen_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/high_noise_patch_gan_generator.pth"
high_noise_disc_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/high_noise_patch_gan_discriminator.pth"
high_noise_history_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/high_noise_patch_gan_training_history.json"

# Initialize GAN Trainer for High Gaussian Noise
high_noise_gan_trainer = GANTrainer(
    generator=high_noise_generator,
    discriminator=high_noise_discriminator,
    train_loader=train_loaders['high_gaussian_noise'],
    val_loader=val_loaders['high_gaussian_noise'],
    gen_optimizer=gen_optimizer,
    disc_optimizer=disc_optimizer,
    gen_criterion=gen_criterion,
    device=device
)

print("\nStarting Training for High Gaussian Noise:")
high_noise_gan_trainer.fit(
    num_epochs=20,
    gen_save_path=high_noise_gen_path,
    disc_save_path=high_noise_disc_path,
    history_path=high_noise_history_path
)

"""##### V2"""

# Define optimizer and loss function for the new task
gen_optimizer = torch.optim.Adam(high_noise_generator.parameters(), lr=1e-4)
disc_optimizer = torch.optim.Adam(high_noise_discriminator.parameters(), lr=1e-4)
gen_criterion = torch.nn.MSELoss()  # Adjust loss function if needed

# Define save paths for the new task
high_noise_gen_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/high_noise_patch_gan_generator_v2.pth"
high_noise_disc_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/high_noise_patch_gan_discriminator_v2.pth"
high_noise_history_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/high_noise_patch_gan_training_history_v2.json"

# Initialize GAN Trainer for High Gaussian Noise
high_noise_gan_trainer = GANTrainer(
    generator=high_noise_generator,
    discriminator=high_noise_discriminator,
    train_loader=train_loaders['high_gaussian_noise'],
    val_loader=val_loaders['high_gaussian_noise'],
    gen_optimizer=gen_optimizer,
    disc_optimizer=disc_optimizer,
    gen_criterion=gen_criterion,
    device=device
)

print("\nStarting Training for High Gaussian Noise:")
high_noise_gan_trainer.fit(
    num_epochs=20,
    gen_save_path=high_noise_gen_path,
    disc_save_path=high_noise_disc_path,
    history_path=high_noise_history_path
)

"""##### V1"""

# Plot training history
plot_gan_training_history(high_noise_gan_trainer)

"""##### V2"""

# Plot training history
plot_gan_training_history(high_noise_gan_trainer)

# Evaluate the GAN on the high Gaussian noise test set
test_loss, test_psnr, test_ssim = evaluate_gan_on_test_set(
    high_noise_generator,
    test_loaders['high_gaussian_noise'],
    gen_criterion,
    device
)

"""##### V1"""

print(f"\nHigh Gaussian Noise Test Set Metrics:\nLoss: {test_loss:.4f}, PSNR: {test_psnr:.4f}, SSIM: {test_ssim:.4f}")
# Visualize predictions for high Gaussian noise test set
visualize_gan_predictions(high_noise_generator, test_loaders['high_gaussian_noise'], device=device, num_samples=5)

"""##### V2"""

print(f"\nHigh Gaussian Noise Test Set Metrics:\nLoss: {test_loss:.4f}, PSNR: {test_psnr:.4f}, SSIM: {test_ssim:.4f}")
# Visualize predictions for high Gaussian noise test set
visualize_gan_predictions(high_noise_generator, test_loaders['high_gaussian_noise'], device=device, num_samples=5)

"""## Task 3: Denosing Salt and Pepper Noise

### AttentionUnet
"""

# Load model with pretrained weights from high Gaussian noise
model = AttentionUNet(in_channels=1, out_channels=1).to(device)

# Load weights from the high Gaussian noise task
high_noise_model_path = get_model_save_path(dataset_base_path, filename="attention_unet_best_model_high_noise.pth")
model.load_state_dict(torch.load(high_noise_model_path))
print(f"Loaded pretrained weights from: {high_noise_model_path}")

# Visualize salt-and-pepper noise dataset
print("Visualizing Salt-and-Pepper Noise:")
visualize_noisy_clean(train_loaders['salt_pepper_noise'])

# Update optimizer and scheduler for fine-tuning
optimizer = optim.Adam(model.parameters(), lr=1e-3)  # Slightly higher learning rate for fine-tuning
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=3, factor=0.5)

# Save path for salt-and-pepper noise training
sp_noise_model_path = get_model_save_path(dataset_base_path, filename="attention_unet_best_model_salt_pepper_noise.pth")

# Initialize Trainer for salt-and-pepper noise
trainer = Trainer(
    model=model,
    train_loader=train_loaders['salt_pepper_noise'],
    val_loader=val_loaders['salt_pepper_noise'],
    optimizer=optimizer,
    criterion=criterion,
    scheduler=scheduler,
    device=device
)

# Train the model on salt-and-pepper noise
print("\nStarting Training for Salt-and-Pepper Noise:")
trainer.fit(num_epochs=20, save_path=sp_noise_model_path)

print(f"\nTraining completed for Salt-and-Pepper Noise. Model saved at: {sp_noise_model_path}")

# Call the function after training
plot_training_history(trainer)

# Evaluate the model on the salt-and-pepper noise test set
test_loss, test_psnr, test_ssim = evaluate_on_test_set(
    model,
    test_loaders['salt_pepper_noise'],
    criterion,
    device
)
print(f"\nSalt-and-Pepper Noise Test Set Metrics:\nLoss: {test_loss:.4f}, PSNR: {test_psnr:.4f}, SSIM: {test_ssim:.4f}")

# Visualize predictions for salt-and-pepper noise test set
visualize_predictions(model, test_loaders['salt_pepper_noise'], device=device, num_samples=5)



"""### AttentionPatchGAN

##### V2
"""

# Load Pretrained Generator for High Gaussian Noise
sp_noise_generator = AttentionUNet().to(device)
# high_noise_gen_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/high_noise_patch_gan_generator_v2.pth"
# sp_noise_generator.load_state_dict(torch.load(high_noise_gen_path))
# print(f"Loaded pretrained generator weights from: {high_noise_gen_path}")

# Load Pretrained Discriminator for High Gaussian Noise
sp_noise_discriminator = PatchGANDiscriminator(in_channels=2, base_channels=32, stride=[2, 1, 1, 1, 1, 1], padding=[1, 0, 0, 0, 0, 0]).to(device)
# high_noise_disc_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/high_noise_patch_gan_discriminator_v2.pth"
# sp_noise_discriminator.load_state_dict(torch.load(high_noise_disc_path))
# print(f"Loaded pretrained discriminator weights from: {high_noise_disc_path}")

# Visualize salt-and-pepper noise dataset
print("Visualizing Salt-and-Pepper Noise:")
visualize_noisy_clean(train_loaders['salt_pepper_noise'])

# Define optimizer and loss function for the new task
gen_optimizer = torch.optim.Adam(sp_noise_discriminator.parameters(), lr=1e-4)
disc_optimizer = torch.optim.Adam(sp_noise_discriminator.parameters(), lr=1e-4)
gen_criterion = torch.nn.MSELoss()  # Adjust loss function if needed

# Define save paths for the new task
sp_noise_gen_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/sp_noise_patch_gan_generator_v2.pth"
sp_noise_disc_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/sp_noise_patch_gan_discriminator_v2.pth"
sp_noise_history_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/sp_noise_patch_gan_training_history_v2.json"

# Initialize GAN Trainer for sp Gaussian Noise
sp_noise_gan_trainer = GANTrainer(
    generator=sp_noise_generator,
    discriminator=sp_noise_discriminator,
    train_loader=train_loaders['salt_pepper_noise'],
    val_loader=val_loaders['salt_pepper_noise'],
    gen_optimizer=gen_optimizer,
    disc_optimizer=disc_optimizer,
    gen_criterion=gen_criterion,
    device=device
)


print("\nStarting Training for sp Gaussian Noise:")
sp_noise_gan_trainer.fit(
    num_epochs=40,
    gen_save_path=sp_noise_gen_path,
    disc_save_path=sp_noise_disc_path,
    history_path=sp_noise_history_path
)

# Call the function after training
plot_training_history(trainer)

# Evaluate the model on the salt-and-pepper noise test set
test_loss, test_psnr, test_ssim = evaluate_on_test_set(
    model,
    test_loaders['salt_pepper_noise'],
    criterion,
    device
)
print(f"\nSalt-and-Pepper Noise Test Set Metrics:\nLoss: {test_loss:.4f}, PSNR: {test_psnr:.4f}, SSIM: {test_ssim:.4f}")

# Visualize predictions for salt-and-pepper noise test set
visualize_predictions(model, test_loaders['salt_pepper_noise'], device=device, num_samples=5)





"""##### V3"""

# Load Pretrained Generator for High Gaussian Noise
sp_noise_generator = AttentionUNet().to(device)
# high_noise_gen_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/high_noise_patch_gan_generator_v2.pth"
# sp_noise_generator.load_state_dict(torch.load(high_noise_gen_path))
# print(f"Loaded pretrained generator weights from: {high_noise_gen_path}")

# Load Pretrained Discriminator for High Gaussian Noise
sp_noise_discriminator = PatchGANDiscriminator(in_channels=2, base_channels=32, stride=[2, 2, 1, 1, 1, 1], padding=[0, 0, 0, 0, 0, 0], use_fc=True, global_pooling=True).to(device)
# high_noise_disc_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/high_noise_patch_gan_discriminator_v2.pth"
# sp_noise_discriminator.load_state_dict(torch.load(high_noise_disc_path))
# print(f"Loaded pretrained discriminator weights from: {high_noise_disc_path}")

# Define optimizer and loss function for the new task
gen_optimizer = torch.optim.Adam(sp_noise_discriminator.parameters(), lr=1e-4)
disc_optimizer = torch.optim.Adam(sp_noise_discriminator.parameters(), lr=1e-4)
gen_criterion = torch.nn.MSELoss()  # Adjust loss function if needed

# Define save paths for the new task
sp_noise_gen_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/sp_noise_patch_gan_generator_v3.pth"
sp_noise_disc_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/sp_noise_patch_gan_discriminator_v3.pth"
sp_noise_history_path = "/content/drive/My Drive/AI/Computer_vision_Fall2024/HW2/Q2/emotions_data/sp_noise_patch_gan_training_history_v3.json"

# Initialize GAN Trainer for sp Gaussian Noise
sp_noise_gan_trainer = GANTrainer(
    generator=sp_noise_generator,
    discriminator=sp_noise_discriminator,
    train_loader=train_loaders['salt_pepper_noise'],
    val_loader=val_loaders['salt_pepper_noise'],
    gen_optimizer=gen_optimizer,
    disc_optimizer=disc_optimizer,
    gen_criterion=gen_criterion,
    device=device
)


print("\nStarting Training for sp Gaussian Noise:")
sp_noise_gan_trainer.fit(
    num_epochs=50,
    gen_save_path=sp_noise_gen_path,
    disc_save_path=sp_noise_disc_path,
    history_path=sp_noise_history_path
)

# Call the function after training
plot_training_history(trainer)

# Evaluate the model on the salt-and-pepper noise test set
test_loss, test_psnr, test_ssim = evaluate_on_test_set(
    model,
    test_loaders['salt_pepper_noise'],
    criterion,
    device
)
print(f"\nSalt-and-Pepper Noise Test Set Metrics:\nLoss: {test_loss:.4f}, PSNR: {test_psnr:.4f}, SSIM: {test_ssim:.4f}")

# Visualize predictions for salt-and-pepper noise test set
visualize_predictions(model, test_loaders['salt_pepper_noise'], device=device, num_samples=5)